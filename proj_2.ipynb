{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* (6 points) Create your class that implements the Gradient Boosting concept, based on the locally weighted regression method (Lowess class), and that allows a user-prescribed number of boosting steps. The class you develop should have all the mainstream useful options, including “fit,” “is_fitted”,  and “predict,” methods.  Show applications with real data for regression, 10-fold cross-validations and compare the effect of different scalers, such as the “StandardScaler”, “MinMaxScaler”, and the “QuantileScaler”.  In the case of the “Concrete” data set, determine a choice of hyperparameters that yield lower MSEs for your method when compared to the eXtream Gradient Boosting library.\n",
        "\n",
        "* (3 points) Based on the Usearch library, create your own class that computes the k_Nearest Neighbors for Regression.\n",
        "\n",
        "* (1 point) Host your project on your GitHiub page."
      ],
      "metadata": {
        "id": "EIUsMzW_Fhrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computational libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial import Delaunay\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "import scipy.stats as stats\n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy.interpolate import interp1d, RegularGridInterpolator, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
        "from math import ceil\n",
        "from scipy import linalg\n",
        "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
      ],
      "metadata": {
        "id": "5TF8v0cJ6AiV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_scale = StandardScaler()\n",
        "q_scale = QuantileTransformer()\n",
        "mm_scale = MinMaxScaler()"
      ],
      "metadata": {
        "id": "n7Ehmpvp6B2N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files = files.upload()"
      ],
      "metadata": {
        "id": "qMVPIykNFyvR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2b15daae-ff82-4f7b-f72b-a0074aacc379"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ae65199-43e0-4c8c-85b3-228f044af789\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ae65199-43e0-4c8c-85b3-228f044af789\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving concrete.csv to concrete.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('concrete.csv')\n",
        "x = data.loc[:,'cement':'age'].values\n",
        "y = data['strength'].values"
      ],
      "metadata": {
        "id": "O_iLTAF6-NwU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ],
      "metadata": {
        "id": "fGxAF9nU-MKh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1"
      ],
      "metadata": {
        "id": "AboY29lKk1HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Kernel\n",
        "def Gaussian(w):\n",
        "  return np.where(w>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*w**2))\n",
        "\n",
        "# Tricubic Kernel\n",
        "def Tricubic(w):\n",
        "  return np.where(w>1,0,70/81*(1-w**3)**3)\n",
        "\n",
        "# Quartic Kernel\n",
        "def Quartic(w):\n",
        "  return np.where(w>1,0,15/16*(1-w**2)**2)\n",
        "\n",
        "# Epanechnikov Kernel\n",
        "def Epanechnikov(w):\n",
        "  return np.where(w>1,0,3/4*(1-w**2))"
      ],
      "metadata": {
        "id": "ApTpAJVoV7uw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(u,v):\n",
        "  if len(v.shape)==1:\n",
        "    v = v.reshape(1,-1)\n",
        "  d = np.array([np.sqrt(np.sum((u-v[i])**2,axis=1)) for i in range(len(v))])\n",
        "  return d"
      ],
      "metadata": {
        "id": "QhgYRV83V7yI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n"
      ],
      "metadata": {
        "id": "qsc559VhfvQu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_function(u,v,kern=Gaussian,tau=0.5):\n",
        "    return kern(cdist(u, v, metric='euclidean')/(2*tau))"
      ],
      "metadata": {
        "id": "VyBBoQH5fncM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "TMzAZ418fAyP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lw_ag_md(x, y, xnew,f=2/3,iter=3, intercept=True):\n",
        "\n",
        "  n = len(x)\n",
        "  r = int(ceil(f * n))\n",
        "  yest = np.zeros(n)\n",
        "\n",
        "  if len(y.shape)==1: # here we make column vectors\n",
        "    y = y.reshape(-1,1)\n",
        "\n",
        "  if len(x.shape)==1:\n",
        "    x = x.reshape(-1,1)\n",
        "\n",
        "  if intercept:\n",
        "    x1 = np.column_stack([np.ones((len(x),1)),x])\n",
        "  else:\n",
        "    x1 = x\n",
        "\n",
        "  h = [np.sort(np.sqrt(np.sum((x-x[i])**2,axis=1)))[r] for i in range(n)]\n",
        "  # dist(x,x) is always symmetric\n",
        "  w = np.clip(dist(x,x) / np.array(h), 0.0, 1.0)\n",
        "  # note that w is a square matrix and in Python arithmetic operations such as\n",
        "  # w**3 or 1-w**3 are performed element-wise\n",
        "  #w = (1-w**3)**3 # a Tricubic kernel\n",
        "  w = Epanechnikov(w)\n",
        "\n",
        "  #Looping through all X-points\n",
        "  delta = np.ones(n)\n",
        "  for iteration in range(iter):\n",
        "    for i in range(n):\n",
        "      W = np.diag(delta).dot(np.diag(w[i,:]))\n",
        "      # when we multiply two diagonal matrices we get also a diagonal matrix\n",
        "      b = np.transpose(x1).dot(W).dot(y)\n",
        "      A = np.transpose(x1).dot(W).dot(x1)\n",
        "      ##\n",
        "      A = A + 0.0001*np.eye(x1.shape[1]) # if we want L2 regularization for solving the system\n",
        "      beta = linalg.solve(A, b)\n",
        "\n",
        "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
        "      yest[i] = np.dot(x1[i],beta.ravel())\n",
        "\n",
        "    residuals = y.ravel() - yest\n",
        "    s = np.median(np.abs(residuals))\n",
        "\n",
        "    delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
        "\n",
        "    delta = (1 - delta ** 2) ** 2\n",
        "\n",
        "  # here we are making predictions for xnew by using an interpolation and the predictions we made for the train data\n",
        "  if x.shape[1]==1:\n",
        "    f = interp1d(x.flatten(),yest,fill_value='extrapolate')\n",
        "    output = f(xnew)\n",
        "  else:\n",
        "    output = np.zeros(len(xnew))\n",
        "    for i in range(len(xnew)):\n",
        "      ind = np.argsort(np.sqrt(np.sum((x-xnew[i])**2,axis=1)))[:r]\n",
        "      pca = PCA(n_components=3)\n",
        "      x_pca = pca.fit_transform(x[ind])\n",
        "      tri = Delaunay(x_pca,qhull_options='QJ Pp')\n",
        "      f = LinearNDInterpolator(tri,yest[ind])\n",
        "      output[i] = f(pca.transform(xnew[i].reshape(1,-1)))\n",
        "      # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "\n",
        "  if sum(np.isnan(output))>0:\n",
        "    g = NearestNDInterpolator(x,yest.ravel())\n",
        "    # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
        "    output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
        "  return output"
      ],
      "metadata": {
        "id": "K8U2ATu6V71v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lowess:\n",
        "    def __init__(self, kernel = Gaussian, tau=0.05):\n",
        "        self.kernel = kernel\n",
        "        self.tau = tau\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        kernel = self.kernel\n",
        "        tau = self.tau\n",
        "        self.xtrain_ = x\n",
        "        self.yhat_ = y\n",
        "\n",
        "    def predict(self, x_new):\n",
        "        check_is_fitted(self)\n",
        "        x = self.xtrain_\n",
        "        y = self.yhat_\n",
        "        lm = linear_model.Ridge(alpha=0.001)\n",
        "        w = weight_function(x,x_new,self.kernel,self.tau)\n",
        "\n",
        "        if np.isscalar(x_new):\n",
        "          lm.fit(np.diag(w)@(x.reshape(-1,1)),np.diag(w)@(y.reshape(-1,1)))\n",
        "          yest = lm.predict([[x_new]])[0][0]\n",
        "        else:\n",
        "          n = len(x_new)\n",
        "          yest_test = []\n",
        "          #Looping through all x-points\n",
        "          for i in range(n):\n",
        "            lm.fit(np.diag(w[:,i])@x,np.diag(w[:,i])@y)\n",
        "            yest_test.append(lm.predict([x_new[i]]))\n",
        "        return np.array(yest_test).flatten()"
      ],
      "metadata": {
        "id": "Ho-RoPalV74L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = tts(x,y,test_size=0.3,shuffle=True,random_state=123)"
      ],
      "metadata": {
        "id": "4eZm0ios-FzY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mse ~ 58"
      ],
      "metadata": {
        "id": "EG-NOPWX_gW1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalers = [s_scale,q_scale,mm_scale]"
      ],
      "metadata": {
        "id": "y9tE06QPACfK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_mse_lwr = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "model_1 = Lowess(kernel= Gaussian,tau=0.14)\n",
        "model_2 = Lowess(kernel= Epanechnikov,tau=0.05)\n",
        "for scale in scalers:\n",
        "  mse_lwr = []\n",
        "  for idxtrain, idxtest in kf.split(x):\n",
        "    xtrain = x[idxtrain]\n",
        "    ytrain = y[idxtrain].ravel()\n",
        "    ytest = y[idxtest].ravel()\n",
        "    xtest = x[idxtest]\n",
        "    xtrain = scale.fit_transform(xtrain)\n",
        "    xtest = scale.transform(xtest)\n",
        "\n",
        "    model_1.fit(xtrain,ytrain)\n",
        "    yhat_train = model_1.predict(xtrain)\n",
        "    residuals_train = ytrain - yhat_train\n",
        "    model_2.fit(xtrain,residuals_train)\n",
        "    residuals_hat = model_2.predict(xtest)\n",
        "    yhat_lw = model_1.predict(xtest) + model_2.predict(xtest)\n",
        "\n",
        "    mse_lwr.append(mse(ytest,yhat_lw))\n",
        "  mean_mse_lwr.append(np.mean(mse_lwr))\n",
        "\n",
        "\n",
        "print('The Cross-validated Mean Squared Error for Locally Weighted Regression is : '+str(mean_mse_lwr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm3atc-VADO7",
        "outputId": "6d751917-9c8d-4537-d07e-0f9c28a77898"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for Locally Weighted Regression is : [167.06646876133357, 22.09903664018056, 36.616417475594915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost"
      ],
      "metadata": {
        "id": "roX1GesWzfCk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgboost = xgboost.XGBRFRegressor(n_estimators=200,max_depth=7)"
      ],
      "metadata": {
        "id": "sjqGy7pbzj3A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgboost.fit(xtrain,ytrain)\n",
        "mse(ytest,model_xgboost.predict(xtest))"
      ],
      "metadata": {
        "id": "7cwMau6z-pSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60650da4-a8b0-471e-9729-38ccc2270b11"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.443587005918328"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uxk7hPHUktU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a combination of epanechnikov and gaussian kernels and the quantile scaler, i was able to get the boosted regressor to an mse of 22, better than the xgboost benchmark of 27"
      ],
      "metadata": {
        "id": "6YR-x6IPkt8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2"
      ],
      "metadata": {
        "id": "ZIoRKMHXF0Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install usearch"
      ],
      "metadata": {
        "id": "v7kYnuLVF86E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09106abe-d261-4e5b-ae0d-35c9826dfdc1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting usearch\n",
            "  Downloading usearch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from usearch) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from usearch) (4.66.2)\n",
            "Installing collected packages: usearch\n",
            "Successfully installed usearch-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import usearch.index\n",
        "from usearch.index import search, MetricKind, Matches, BatchMatches, Index"
      ],
      "metadata": {
        "id": "mr0XOtBeF1JB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.random.rand(100, 5).astype(np.float32)\n",
        "vector = np.random.rand(5).astype(np.float32)"
      ],
      "metadata": {
        "id": "jov8JQzTF6Gq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_in_many: Matches = search(vectors, vector, 5, MetricKind.L2sq, exact=True)"
      ],
      "metadata": {
        "id": "hC-QKHZQTbtD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(one_in_many[0])"
      ],
      "metadata": {
        "id": "goxKf1pETdxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c9bb35-800f-45a9-dea8-77da10303e5b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "usearch.index.Match"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors)"
      ],
      "metadata": {
        "id": "OnA92lVxITEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b0df9c-48cc-4dc4-c151-d0a7726f6399"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.random.rand(1000, 100).astype(np.float32)\n",
        "len(vectors)\n",
        "vectors.size"
      ],
      "metadata": {
        "id": "fkSxaH1IXVAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93dc0611-39ff-4fc9-97cc-7d93a4620be8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class usearch_knn:\n",
        "    def __init__(self ,max_cs = None,min_cs = None):\n",
        "        self.max_cs = max_cs\n",
        "        self.min_cs = min_cs\n",
        "\n",
        "    def nearest_to_one(self, vectors, vector, n = 15):\n",
        "      result: BatchMatches = search(vectors, vector, 10, MetricKind.L2sq, exact=True)\n",
        "      return result.to_list()\n",
        "\n",
        "\n",
        "    def knn_cluster(self,vectors):\n",
        "      index = Index(\n",
        "          ndim=vectors.shape[-1],\n",
        "          metric='cos'\n",
        "        )\n",
        "      n = len(vectors)\n",
        "      keys = [i for i in range(n)]\n",
        "      index.add(keys,vectors)\n",
        "      clustering = index.cluster(\n",
        "          vectors = vectors,\n",
        "\n",
        "          min_count= self.min_cs,\n",
        "          max_count= self.max_cs\n",
        "      )\n",
        "      return clustering\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SgZzQB34bT3i"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uknn = usearch_knn()\n",
        "clustering = uknn.knn_cluster(vectors)\n",
        "clustering"
      ],
      "metadata": {
        "id": "eIF-E7glOS0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0a360e-e83b-4e7a-c8dc-91620710be57"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "usearch.Clustering(for 1000 queries)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "centroid_keys, sizes = clustering.centroids_popularity"
      ],
      "metadata": {
        "id": "oNoGWRThfSPf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(centroid_keys)"
      ],
      "metadata": {
        "id": "pyxYl_Fef8B1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f63c1b-59b3-4853-a7ab-fd45e438e623"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = []\n",
        "for i in range(len(centroid_keys)):\n",
        "    indices = clustering.members_of(centroid_keys[i])\n",
        "    clusters.append(indices)\n",
        "\n",
        "for i, cluster_indices in enumerate(clusters):\n",
        "    print(f\"Cluster {i}: {cluster_indices}\")"
      ],
      "metadata": {
        "id": "W0Ga5TZ1gO0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab01fbd-d3e6-44fd-dcf0-bb6b4e8c6b10"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0: [  6 113 210 284 285 382 390 520 604 699 861 904]\n",
            "Cluster 1: [  4   8  22  28 276 282 343 432 534 579 590 672 792 807 847]\n",
            "Cluster 2: [ 16  69  84 121 126 131 148 273 288 316 329 335 352 394 474 487 544 581\n",
            " 603 691 749 766 786 793 810 813 816 928 931 934]\n",
            "Cluster 3: [ 15  29 278 317 418 742]\n",
            "Cluster 4: [ 18  38  40  71 152 160 199 229 242 265 274 280 369 456 503 505 655 689\n",
            " 711 714 796 834 852 945 953 999]\n",
            "Cluster 5: [ 53  82 932]\n",
            "Cluster 6: [109]\n",
            "Cluster 7: [  7  44  45  48  57  74  80  95 100 119 125 183 191 194 195 205 212 213\n",
            " 214 220 250 262 263 267 290 305 345 360 361 370 372 377 402 407 409 414\n",
            " 426 427 429 467 507 513 521 535 541 545 549 551 556 558 607 618 631 634\n",
            " 646 657 663 674 675 685 693 705 713 719 722 725 738 773 775 782 784 787\n",
            " 848 864 865 875 881 888 896 898 906 918 924 943 949 970 973 976 978]\n",
            "Cluster 8: [ 39  72 140 171 252 277 318 391 433 448 452 453 527 548 630 673 676 684\n",
            " 878 915 950]\n",
            "Cluster 9: [ 55 151 180 291 342 373 419 926]\n",
            "Cluster 10: [ 19  20  23  87 106 137 156 186 202 261 303 319 332 355 457 479 518 542\n",
            " 568 571 627 645 658 668 704 709 797 798 825 839 843 850 862 886 891 900\n",
            " 937 962 987]\n",
            "Cluster 11: [ 33  41 192 294 359 577 601 653 866 921]\n",
            "Cluster 12: [196]\n",
            "Cluster 13: [145 176 207 243 323 327 375 383 412 486 492 543 555 561 706 776 840 893]\n",
            "Cluster 14: [ 12  32  37  46  49  50  65  75  98 101 111 129 153 154 155 181 187 217\n",
            " 222 248 301 302 325 362 443 472 478 550 570 595 635 670 679 688 694 731\n",
            " 737 741 768 769 780 794 842 851 857 863 872 892 895 912 927 930 941 954\n",
            " 957 964 969 981 995]\n",
            "Cluster 15: [218 916]\n",
            "Cluster 16: [ 31  96 118 159 221 247 270 351 406 430 491 511 537 546 585 652 656 715\n",
            " 740 785 844 845 936 940 963]\n",
            "Cluster 17: [251 256 257 269 292 490 944 998]\n",
            "Cluster 18: [ 36  56  70  73 175 184 240 254 255 259 304 307 324 408 431 445 460 482\n",
            " 664 669 739 836 908 917 923 979 988]\n",
            "Cluster 19: [ 13  17 157 223 279 289 306 321 331 333 344 366 403 441 471 489 531 540\n",
            " 554 573 587 596 598 614 638 643 654 720 736 760 790 822 854 897 902 956\n",
            " 986]\n",
            "Cluster 20: [110 135 300 326 404 755 833 960]\n",
            "Cluster 21: [  3  43  64 253 311 436 501 611 727 746 832 867 980]\n",
            "Cluster 22: [ 47  60 123 312 584 589 641 996]\n",
            "Cluster 23: [328 929]\n",
            "Cluster 24: [293 296 337 636 681 907 909]\n",
            "Cluster 25: [354]\n",
            "Cluster 26: [142 356 569]\n",
            "Cluster 27: [143 322 395]\n",
            "Cluster 28: [ 24  27 158 162 244 357 371 399 458 578 580 582 605 616 682 818 860 879\n",
            " 889 903 933 942 982]\n",
            "Cluster 29: [216 241 313 424 451 477 525 599 716]\n",
            "Cluster 30: [ 58 203 230 233 464 483 515 767 993]\n",
            "Cluster 31: [ 34 112 163 173 201 405 420 499 502 506 514 563 593 626 633 730 733 829\n",
            " 873 901 951]\n",
            "Cluster 32: [107 141 454 466 508 533]\n",
            "Cluster 33: [144 516 753]\n",
            "Cluster 34: [529 574 855]\n",
            "Cluster 35: [ 42  54  88 167 209 227 238 272 469 536 538 647 671 678 697 698 710 777\n",
            " 838 922 966 984]\n",
            "Cluster 36: [260 283 455 553 566 779 849 955]\n",
            "Cluster 37: [557 609 778 819]\n",
            "Cluster 38: [237 340 539 625 952]\n",
            "Cluster 39: [211 271 346 378 380 428 439 446 565 576 640 690 726 744 858 877 887 913]\n",
            "Cluster 40: [  0  52  83 108 124 134 138 178 224 249 350 398 413 423 435 509 572 597\n",
            " 608 680 683 687 700 723 729 732 734 756 821 874 880]\n",
            "Cluster 41: [102 200 206 295 368 388 397 528 567 575 620 686 846 871 939]\n",
            "Cluster 42: [ 91  94 132 150 179 189 219 258 309 364 374 393 434 475 495 497 532 600\n",
            " 615 692 770 803 823 835 841 890 911]\n",
            "Cluster 43: [523 696 703 751 774 801 925 948]\n",
            "Cluster 44: [  1   2  14  26  68  78  85 114 117 120 139 161 236 281 299 330 334 363\n",
            " 386 400 410 411 416 438 442 461 465 473 476 484 493 519 588 594 606 644\n",
            " 659 666 701 707 745 748 754 808 814 817 868 961 967 968 985 992]\n",
            "Cluster 45: [ 10  11  30  51  66  77  79  86  89  93  99 105 115 122 127 128 130 133\n",
            " 136 146 149 164 165 166 169 172 182 188 190 204 208 215 226 232 234 245\n",
            " 246 266 314 315 320 336 341 349 358 367 376 384 385 389 392 415 421 425\n",
            " 440 447 450 459 463 470 485 498 500 526 559 560 562 583 586 592 612 621\n",
            " 628 639 651 661 662 665 677 695 702 717 762 763 764 771 772 783 788 795\n",
            " 802 804 805 815 824 831 837 853 859 869 876 883 884 910 914 919 935 938\n",
            " 947 965 972 975 989 994]\n",
            "Cluster 46: [ 59 417 660 718]\n",
            "Cluster 47: [ 61 103 231 353 449 564 623 747 765 781 791 809 905]\n",
            "Cluster 48: [  9  21  25  90 104 174 198 239 268 286 297 298 387 444 481 496 510 517\n",
            " 530 547 591 610 613 632 649 650 708 735 743 757 806 820 830 885 946 958\n",
            " 959 990 991]\n",
            "Cluster 49: [ 62  97 116 228 365 381 480 522 524 619 642 712 721 759 870]\n",
            "Cluster 50: [ 76 264 347 488 789 997]\n",
            "Cluster 51: [  5  35 275 310 437 512 552 728 799 800 894]\n",
            "Cluster 52: [637 811 826]\n",
            "Cluster 53: [177 396 812 971]\n",
            "Cluster 54: [828]\n",
            "Cluster 55: [494 856]\n",
            "Cluster 56: [170 339 348 379 504 617 622 629 750 761 899]\n",
            "Cluster 57: [ 63  67  81  92 147 168 225 235 287 308 422 468 602 624 648 667 724 752\n",
            " 758 827 882 974 977]\n",
            "Cluster 58: [185 193 197 338 401 462 920 983]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.random.rand(10000, 1024).astype(np.float32)\n",
        "vector = np.random.rand(1024).astype(np.float32)"
      ],
      "metadata": {
        "id": "pnnSwLfxi-dw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uknn.nearest_to_one(vectors,vector)"
      ],
      "metadata": {
        "id": "VeOHg154uKX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f00b70d-c950-4a0c-86a5-052a9e0d1523"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1407, 150.5949249267578),\n",
              " (792, 151.77407836914062),\n",
              " (2505, 151.8466339111328),\n",
              " (4716, 152.25698852539062),\n",
              " (4641, 152.3251190185547),\n",
              " (5956, 152.78082275390625),\n",
              " (6890, 152.8309326171875),\n",
              " (3278, 152.92190551757812),\n",
              " (4350, 153.02426147460938),\n",
              " (7683, 153.09165954589844)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBTs5tKMuTB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}